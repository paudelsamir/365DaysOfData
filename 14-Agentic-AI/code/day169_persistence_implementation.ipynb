{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010fcc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END \n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "import datetime, json, os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf9a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(model='llama3.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a660de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator_tool(state):\n",
    "    user_message = state[\"user_message\"].content\n",
    "    try:\n",
    "        result = eval(user_message)\n",
    "        reply = f\"the result of {user_message} is {result}.\"\n",
    "    except Exception as e:\n",
    "        reply = f\"error in calculation: {str(e)}\"\n",
    "    return {\"messages\": add_messages(state[\"messages\"], [AIMessage(content=reply)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_tool(state):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    return {\"messages\": add_messages(state[\"messages\"], [AIMessage(content=f\"the current date and time is: {current_time}\")])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smalltalk_node(state):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": add_messages(state[\"messages\"], [AIMessage(content=response.content)])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c4da83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state):\n",
    "    last_user_message = state[\"user_message\"].content.lower()\n",
    "    if any(k in last_user_message for k in [\"calculate\", \"what is\", \"solve\", \"+\", \"-\", \"*\", \"/\"]):\n",
    "        return \"calculator\"\n",
    "    elif any(k in last_user_message for k in [\"time\", \"date\", \"day\", \"now\"]):\n",
    "        return \"time\"\n",
    "    else:\n",
    "        return \"smalltalk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2c374ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7fa1c25d7750>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = StateGraph(dict)\n",
    "\n",
    "graph.add_node('calculator', calculator_tool)\n",
    "graph.add_node('time', time_tool)\n",
    "graph.add_node('smalltalk', smalltalk_node)\n",
    "\n",
    "\n",
    "graph.add_conditional_edges(START, router, {\n",
    "    \"calculator\": \"calculator\",\n",
    "    \"time\": \"time\",\n",
    "    \"smalltalk\": \"smalltalk\"\n",
    "})\n",
    "\n",
    "graph.add_edge('calculator', END)\n",
    "graph.add_edge('time', END)\n",
    "graph.add_edge('smalltalk', END)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c3cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c387068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c7d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai: How can I assist you today?\n",
      "ai: I'm just a computer program, so I don't have feelings or emotions like humans do. But I'm functioning properly and ready to help with any questions or tasks you may have! How about you? How's your day going?\n",
      "ai: Hello Samir Paudel! It's nice to meet you. Is there something on your mind that you'd like to talk about, or are you looking for assistance with something specific? I'm all ears (or rather, all text).\n",
      "ai: Your name is Samir Paudel! You told me that earlier when we started chatting. Is everything okay?\n",
      "ai: I don't have the ability to save or store our conversation anywhere. I'm a stateless AI model, which means that each time you interact with me, it's a new session and I don't retain any information from previous conversations.\n",
      "\n",
      "When you close this chat window or exit the platform, all of our conversation will be lost. If you want to pick up where we left off, feel free to start a new conversation with me anytime!\n",
      "conversation saved. restart to continue.\n"
     ]
    }
   ],
   "source": [
    "thread_id = \"chat1\"   # unique id for this conversation\n",
    "state = {\"messages\": []}\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"you: \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"conversation saved. restart to continue.\")\n",
    "        break\n",
    "    \n",
    "    # add user message\n",
    "    state[\"messages\"] = add_messages(state[\"messages\"], [HumanMessage(content=user_input)])\n",
    "    state[\"user_message\"] = HumanMessage(content=user_input)\n",
    "    \n",
    "    # run with checkpoint (thread_id ensures continuity)\n",
    "    state = app.invoke(state, config={\"configurable\": {\"thread_id\": thread_id}})\n",
    "    \n",
    "    # print the ai's latest response\n",
    "    print(\"you:\", user_input)\n",
    "    print(\"ai:\", state[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c33913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
