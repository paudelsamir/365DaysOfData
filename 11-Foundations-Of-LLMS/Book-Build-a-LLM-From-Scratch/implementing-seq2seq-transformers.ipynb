{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e867e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github\\365DaysOfData\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"hf://datasets/nirajandhakal/Devnagari-Romanized-Pair/English-Nepali Text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe02330e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Nepali Translation</th>\n",
       "      <th>Nepali Romanized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am going to the market to buy some vegetable...</td>\n",
       "      <td>म बजारमा केही तरकारी र फलफूल किन्न जाँदैछु।</td>\n",
       "      <td>Ma bajaarma kehi tarkari ra phalaphul kinna ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you need any help, please don't hesitate to...</td>\n",
       "      <td>यदि तपाईंलाई कुनै मद्दत चाहिएमा, कृपया मलाई सो...</td>\n",
       "      <td>Yadi tapaailaai kunai maddat chaahieema, kripa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I would like to book a room in a hotel near th...</td>\n",
       "      <td>म एयरपोर्ट नजिकैको होटलमा कोठा बुक गर्न चाहन्छु।</td>\n",
       "      <td>Ma airport najikkai ko hotelma kotha book garn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Could you please tell me how to get to the nea...</td>\n",
       "      <td>कृपया मलाई नजिकको बस स्टेशन कसरी पुग्ने बताउन ...</td>\n",
       "      <td>Kripaya malai najikko bus station kasari pugne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I am interested in learning more about Nepali ...</td>\n",
       "      <td>मलाई नेपाली संस्कृति र परम्पराको बारेमा थप जान...</td>\n",
       "      <td>Malai Nepali sanskriti ra parampara ko baarema...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             English  \\\n",
       "0  I am going to the market to buy some vegetable...   \n",
       "1  If you need any help, please don't hesitate to...   \n",
       "2  I would like to book a room in a hotel near th...   \n",
       "3  Could you please tell me how to get to the nea...   \n",
       "4  I am interested in learning more about Nepali ...   \n",
       "\n",
       "                                  Nepali Translation  \\\n",
       "0        म बजारमा केही तरकारी र फलफूल किन्न जाँदैछु।   \n",
       "1  यदि तपाईंलाई कुनै मद्दत चाहिएमा, कृपया मलाई सो...   \n",
       "2   म एयरपोर्ट नजिकैको होटलमा कोठा बुक गर्न चाहन्छु।   \n",
       "3  कृपया मलाई नजिकको बस स्टेशन कसरी पुग्ने बताउन ...   \n",
       "4  मलाई नेपाली संस्कृति र परम्पराको बारेमा थप जान...   \n",
       "\n",
       "                                    Nepali Romanized  \n",
       "0  Ma bajaarma kehi tarkari ra phalaphul kinna ja...  \n",
       "1  Yadi tapaailaai kunai maddat chaahieema, kripa...  \n",
       "2  Ma airport najikkai ko hotelma kotha book garn...  \n",
       "3  Kripaya malai najikko bus station kasari pugne...  \n",
       "4  Malai Nepali sanskriti ra parampara ko baarema...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435d0b0c",
   "metadata": {},
   "source": [
    "#### OKAY, let's build seq2seq architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37af699e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I am going to the market to buy some vegetables and fruits.',\n",
       "  'म बजारमा केही तरकारी र फलफूल किन्न जाँदैछु।'],\n",
       " [\"If you need any help, please don't hesitate to ask me.\",\n",
       "  'यदि तपाईंलाई कुनै मद्दत चाहिएमा, कृपया मलाई सोध्न नहिचकिचाउनुहोस्।'],\n",
       " ['I would like to book a room in a hotel near the airport.',\n",
       "  'म एयरपोर्ट नजिकैको होटलमा कोठा बुक गर्न चाहन्छु।'],\n",
       " ['Could you please tell me how to get to the nearest bus station?',\n",
       "  'कृपया मलाई नजिकको बस स्टेशन कसरी पुग्ने बताउन सक्नुहुन्छ?'],\n",
       " ['I am interested in learning more about Nepali culture and traditions.',\n",
       "  'मलाई नेपाली संस्कृति र परम्पराको बारेमा थप जान्न मन छ।']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs = df[[\"English\", \"Nepali Translation\"]].values.tolist()\n",
    "\n",
    "pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f6ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "random.shuffle(pairs)\n",
    "\n",
    "train_pairs = pairs[:int(len(pairs) * 0.8)]\n",
    "val_pairs = pairs[int(len(pairs) * 0.8):int(len(pairs) * 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8fa327c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This period could redefine our economic, cultural, technological aspects.',\n",
       "  'यो अवधिले हाम्रो आर्थिक, सांस्कृतिक, प्राविधिक पक्षहरूलाई पुन: परिभाषित गर्न सक्छ।'],\n",
       " ['This perspective, though now known to be flawed, provided a new direction in the treatment of cancer, and moved beyond the humoral theories.',\n",
       "  'यो परिप्रेक्ष्य, अहिले त्रुटिपूर्ण भएको थाहा भए पनि, क्यान्सरको उपचारमा नयाँ दिशा प्रदान गर्\\u200dयो, र हास्य सिद्धान्तहरूभन्दा पर गयो।'],\n",
       " ['The MS-ring functions as a rotating anchor.',\n",
       "  'MS-रिङले घुम्ने एंकरको रूपमा कार्य गर्दछ।'],\n",
       " ['Expanded Analysis: Unveiling the Krebs Cycle: A Central Hub of Cellular Respiration',\n",
       "  'विस्तारित विश्लेषण: क्रेब्स चक्रको अनावरण: सेलुलर श्वासप्रश्वासको एक केन्द्रीय केन्द्र'],\n",
       " ['Ridley’s quote, \"The two chromosomes no longer have each other’s interests at heart, let alone those of the species as a whole,\" underscores this crucial point. He demonstrates the way that selection at the level of the gene can lead to outcomes that appear contrary to the interests of the organism.',\n",
       "  'रिडलेको उद्धरण, \"दुई क्रोमोजोमहरू अब एकअर्काको हितलाई मनमा राख्दैनन्, प्रजातिहरूको समग्र रूपमा त कुरै छोडौं,\" यस महत्त्वपूर्ण कुरालाई जोड दिन्छ। उहाँले देखाउनुहुन्छ कि जीनको स्तरमा चयनले त्यस्ता परिणामहरू निम्त्याउन सक्छ जुन जीवको हितको विपरीत देखिन्छ।']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f038202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in d:\\github\\365daysofdata\\venv\\lib\\site-packages (3.8.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (0.16.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.14)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.1.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.0.post1)\n",
      "Requirement already satisfied: wrapt in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: nltk in d:\\github\\365daysofdata\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from nltk) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in d:\\github\\365daysofdata\\venv\\lib\\site-packages (4.54.1)\n",
      "Requirement already satisfied: filelock in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: colorama in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github\\365daysofdata\\venv\\lib\\site-packages (from requests->transformers) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy\n",
    "%pip install nltk\n",
    "%pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be30d587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\samir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whitespace: ['I', 'am', 'learning', 'NLP.']\n",
      "Regex: ['I', 'am', 'learning', 'NLP']\n",
      "NLTK: ['I', 'am', 'learning', 'NLP', '.']\n",
      "spaCy: ['I', 'am', 'learning', 'NLP', '.']\n",
      "Subword: ['i', 'am', 'learning', 'nl', '##p', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 1. Whitespace Tokenization\n",
    "text = \"I am learning NLP.\"\n",
    "tokens_whitespace = text.split()\n",
    "\n",
    "# 2. Regex Tokenization\n",
    "tokens_regex = re.findall(r'\\b\\w+\\b', text)\n",
    "\n",
    "# 3. NLTK Word Tokenizer\n",
    "nltk.download('punkt_tab')\n",
    "tokens_nltk = word_tokenize(text)\n",
    "\n",
    "# 4. spaCy Tokenizer\n",
    "nlp = spacy.blank(\"en\")\n",
    "tokens_spacy = [token.text for token in nlp(text)]\n",
    "\n",
    "# 5. Subword Tokenization (e.g., Byte Pair Encoding)\n",
    "# Example using HuggingFace's tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "tokens_subword = tokenizer.tokenize(text)\n",
    "\n",
    "print(\"Whitespace:\", tokens_whitespace) \n",
    "print(\"Regex:\", tokens_regex)\n",
    "print(\"NLTK:\", tokens_nltk)\n",
    "print(\"spaCy:\", tokens_spacy)\n",
    "print(\"Subword:\", tokens_subword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98a77e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_english(sentence):\n",
    "    return word_tokenize(sentence)  # NLTK tokenizer for English\n",
    "\n",
    "def tokenize_nepali(sentence):\n",
    "    # Assuming a simple whitespace tokenizer for Nepali\n",
    "    return sentence.split()  # Basic whitespace tokenizer for Nepali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd457605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(sentences, language_tokenizer):\n",
    "    counter = Counter()\n",
    "\n",
    "    for sent in sentences:\n",
    "        tokens = language_tokenizer(sent)\n",
    "        counter.update(tokens)\n",
    "\n",
    "        vocab = {\n",
    "            \"<pad>\": 0,\n",
    "            \"<sos>\": 1,\n",
    "            \"<eos>\": 2,\n",
    "            \"<unk>\": 3\n",
    "        }\n",
    "\n",
    "        \n",
    "        idx = 4 # we need this to start from 4 because we already have 4 special tokens\n",
    "        for word, count in counter.items():\n",
    "            if count >= 2:\n",
    "                vocab[word] = idx\n",
    "                idx += 1\n",
    "\n",
    "\n",
    "    return vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90bd7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sentences = [src for src, tgt in train_pairs]\n",
    "tgt_sentences = [tgt for src, tgt in train_pairs]\n",
    "\n",
    "src_vocab = build_vocab(src_sentences, tokenize_english)\n",
    "tgt_vocab = build_vocab(tgt_sentences, tokenize_nepali)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "392f49cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['The reduction of oxygen by electrons and protons is a very important step as it forms water (H2O), completing the sequence.',\n",
       "  'Hawking presents two main approaches to resolve these paradoxes.',\n",
       "  'Hawking\\'s exploration of extraterrestrial life transcends the usual science fiction tropes; it\\'s rooted in a careful analysis of what constitutes \"life\" itself.',\n",
       "  'Chapter 3, titled \"The Goodness of Show Business,\" marks a pivotal transition point, shifting the narrative away from the focus on the physical act of surgery and towards the transformative potential of chemotherapy.',\n",
       "  'This transfer of electrons is coupled with the pumping of two protons (H<sup>+</sup>) from the matrix to the intermembrane space, thereby adding to the overall proton gradient.'],\n",
       " ['इलेक्ट्रोन र प्रोटोनहरूद्वारा अक्सिजनको कमी एक धेरै महत्त्वपूर्ण चरण हो किनकि यसले पानी (H2O) बनाउँछ, क्रम पूरा गर्दछ।',\n",
       "  'हकिङले यी विरोधाभासहरू समाधान गर्न दुई मुख्य दृष्टिकोण प्रस्तुत गर्नुहुन्छ।',\n",
       "  'हकिङको बाह्य जीवनको खोज सामान्य विज्ञान काल्पनिक कुराहरू भन्दा पर जान्छ; यो \"जीवन\" भनेको के हो भन्ने कुराको सावधानीपूर्वक विश्लेषणमा आधारित छ।',\n",
       "  '\"शो बिजनेसको भलाइ\" शीर्षकको अध्याय ३ ले शल्यक्रियाको भौतिक कार्यमा केन्द्रित हुनुबाट कथालाई रसायन चिकित्साको परिवर्तनकारी सम्भावनातर्फ परिवर्तन गर्दै एउटा महत्वपूर्ण मोडलाई चिन्हित गर्दछ।',\n",
       "  'इलेक्ट्रोनहरूको यो स्थानान्तरण दुई प्रोटोनहरू (H<sup>+</sup>) लाई मैट्रिक्सबाट अन्तरझिल्ली स्पेसमा पम्पिंगसँग जोडिएको छ, जसले गर्दा समग्र प्रोटोन ग्रेडियन्टमा थपिन्छ।'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_sentences[10:15], tgt_sentences[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82e81e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197, 2350)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_vocab), len(tgt_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b518d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(sentence, vocab, tokenizer, add_sos_eos=False):\n",
    "    tokens = tokenizer(sentence)\n",
    "\n",
    "    ids = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "    if add_sos_eos:\n",
    "        ids = [vocab[\"<sos>\"]] + ids + [vocab[\"<eos>\"]]\n",
    "\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc4d48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b8fde57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pairs, src_vocab, tgt_vocab, src_tokenizer, tgt_tokenizer):\n",
    "        self.pairs = pairs\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src, tgt = self.pairs[idx]\n",
    "\n",
    "        src_tensor = torch.tensor(numericalize(src, self.src_vocab, self.src_tokenizer), dtype=torch.long)\n",
    "        tgt_tensor = torch.tensor(numericalize(tgt, self.tgt_vocab, self.tgt_tokenizer, add_sos_eos=True), dtype=torch.long)\n",
    "\n",
    "        return src_tensor, tgt_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4a1837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "\tsrc_batch, tgt_batch = zip(*batch)\n",
    "\tsrc_batch = pad_sequence(src_batch, padding_value=src_vocab['<pad>'], batch_first=True)\n",
    "\ttgt_batch = pad_sequence(tgt_batch, padding_value=tgt_vocab['<pad>'], batch_first=True)\n",
    "\treturn src_batch, tgt_batch\n",
    "\n",
    "train_dataset = TranslationDataset(train_pairs, src_vocab, tgt_vocab, tokenize_english, tokenize_nepali)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48d73367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "src_lengths = [len(tokenize_english(s)) for s, _ in train_pairs]\n",
    "tgt_lengths = [len(tokenize_nepali(t)) for _, t in train_pairs]\n",
    "\n",
    "plt.scatter(src_lengths, tgt_lengths, alpha=0.3)\n",
    "plt.xlabel(\"English sentence length\")\n",
    "plt.ylabel(\"Nepali sentence length\")\n",
    "plt.title(\"Length correlation\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f6d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocab size: 2197\n",
      "Nepali vocab size : 2350\n"
     ]
    }
   ],
   "source": [
    "print(f\"English vocab size: {len(src_vocab)}\")\n",
    "print(f\"Nepali vocab size : {len(tgt_vocab)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "974e0898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 ENGLISH words:\n",
      "[('the', 1533), (',', 1528), ('of', 1093), ('.', 1034), ('and', 673), ('a', 640), ('to', 520), ('that', 354), ('in', 320), ('is', 319), ('as', 212), ('This', 209), ('The', 207), ('for', 171), ('’', 148), (':', 140), ('on', 138), ('it', 134), ('with', 120), ('by', 112)]\n",
      "\n",
      "Top 20 NEPALI words:\n",
      "[('र', 670), ('यो', 325), ('एक', 270), ('रूपमा', 265), ('लागि', 176), ('गर्न', 154), ('जसले', 139), ('कि', 133), ('गर्दछ।', 117), ('जुन', 113), ('पनि', 108), ('यसले', 98), ('यी', 90), ('को', 84), ('महत्त्वपूर्ण', 79), ('ऊर्जा', 75), ('छ।', 71), ('गर्दछ,', 68), ('गर्ने', 66), ('धेरै', 63)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "src_words = Counter()\n",
    "tgt_words = Counter()\n",
    "\n",
    "for s, t in train_pairs:\n",
    "    src_words.update(tokenize_english(s))\n",
    "    tgt_words.update(tokenize_nepali(t))\n",
    "\n",
    "print(\"Top 20 ENGLISH words:\")\n",
    "print(src_words.most_common(20))\n",
    "\n",
    "print(\"\\nTop 20 NEPALI words:\")\n",
    "print(tgt_words.most_common(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6b84d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_batch = pad_sequence(src_batch, padding_value=src_vocab['<pad>'], batch_first=True)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=tgt_vocab['<pad>'], batch_first=True)\n",
    "    return src_batch, tgt_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d7fa226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aaa2c95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderLSTM(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(2197, 300)\n",
      "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p):\n",
    "    super(EncoderLSTM, self).__init__()\n",
    "\n",
    "    # Size of the one hot vectors that will be the input to the encoder\n",
    "    #self.input_size = input_size\n",
    "\n",
    "    # Output size of the word embedding NN\n",
    "    #self.embedding_size = embedding_size\n",
    "\n",
    "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # Number of layers in the lstm\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # Regularization parameter\n",
    "    self.dropout = nn.Dropout(p)\n",
    "    self.tag = True\n",
    "\n",
    "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
    "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "    \n",
    "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
    "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
    "\n",
    "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "    \n",
    "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
    "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
    "\n",
    "    return hidden_state, cell_state\n",
    "\n",
    "# Set device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "input_size_encoder = len(src_vocab)  # Size of the vocabulary for the source language (English)\n",
    "encoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "\n",
    "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
    "                           hidden_size, num_layers, encoder_dropout).to(device)\n",
    "print(encoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f820ab54",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDecoderLSTM\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(DecoderLSTM, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size):\n",
    "    super(DecoderLSTM, self).__init__()\n",
    "\n",
    "    # Size of the one hot vectors that will be the input to the encoder\n",
    "    #self.input_size = input_size\n",
    "\n",
    "    # Output size of the word embedding NN\n",
    "    #self.embedding_size = embedding_size\n",
    "\n",
    "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    # Number of layers in the lstm\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
    "    self.output_size = output_size\n",
    "\n",
    "    # Regularization parameter\n",
    "    self.dropout = nn.Dropout(p)\n",
    "\n",
    "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
    "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "\n",
    "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
    "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p)\n",
    "\n",
    "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  # Shape of x (32) [batch_size]\n",
    "  def forward(self, x, hidden_state, cell_state):\n",
    "\n",
    "    # Shape of x (1, 32) [1, batch_size]\n",
    "    x = x.unsqueeze(0)\n",
    "\n",
    "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
    "    embedding = self.dropout(self.embedding(x))\n",
    "\n",
    "    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
    "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
    "\n",
    "    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n",
    "    predictions = self.fc(outputs)\n",
    "\n",
    "    # Shape --> predictions (32, 4556) [batch_size , output_size]\n",
    "    predictions = predictions.squeeze(0)\n",
    "\n",
    "    return predictions, hidden_state, cell_state\n",
    "\n",
    "input_size_decoder = len(src_vocab)\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2\n",
    "decoder_dropout = 0.5\n",
    "output_size = len(tgt_vocab)\n",
    "\n",
    "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
    "                           hidden_size, num_layers, decoder_dropout, output_size).to(device)\n",
    "print(decoder_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7441396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 102])\n",
      "torch.Size([32, 75])\n",
      "tensor([   1,  148,    3, 2329,  997,   61,  456, 1211,    2,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0].shape)  # src shape\n",
    "    print(batch[1].shape)  # tgt shape\n",
    "    break\n",
    "\n",
    "x = batch[1][1]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffceda3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
    "    super(Seq2Seq, self).__init__()\n",
    "    self.Encoder_LSTM = Encoder_LSTM\n",
    "    self.Decoder_LSTM = Decoder_LSTM\n",
    "\n",
    "  def forward(self, source, target, tfr=0.5):\n",
    "    # Shape - Source : (10, 32) [(Sentence length German + some padding), Number of Sentences]\n",
    "    batch_size = source.shape[1]\n",
    "\n",
    "    # Shape - Source : (14, 32) [(Sentence length English + some padding), Number of Sentences]\n",
    "    target_len = target.shape[0]\n",
    "    target_vocab_size = len(src_vocab.vocab)\n",
    "    \n",
    "    # Shape --> outputs (14, 32, 5766) \n",
    "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
    "\n",
    "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
    "    hidden_state, cell_state = self.Encoder_LSTM(source)\n",
    "\n",
    "    # Shape of x (32 elements)\n",
    "    x = target[0] # Trigger token <SOS>\n",
    "\n",
    "    for i in range(1, target_len):\n",
    "      # Shape --> output (32, 5766) \n",
    "      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
    "      outputs[i] = output\n",
    "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
    "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
    "\n",
    "    # Shape --> outputs (14, 32, 5766) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01f9f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# import torch and nn modules for building neural networks\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the transformer encoder class\n",
    "class TransformerEncoder(nn.Module):\n",
    "    # initialize the encoder with all required parameters\n",
    "    def __init__(self, input_size, embedding_size, num_heads, hidden_size, num_layers, max_len, p):\n",
    "        # call the parent class constructor\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        # create token embedding layer for input tokens\n",
    "        self.token_embedding = nn.Embedding(input_size, embedding_size)\n",
    "        # create position embedding layer for positional information\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        # create dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        # create a transformer encoder layer with specified parameters\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embedding_size,      # set the embedding dimension\n",
    "            nhead=num_heads,             # set the number of attention heads\n",
    "            dim_feedforward=hidden_size, # set the hidden size for feedforward network\n",
    "            dropout=p,                   # set dropout probability\n",
    "            batch_first=True             # use (batch, seq, embed) format\n",
    "        )\n",
    "        # stack multiple encoder layers to form the full encoder\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    # define the forward pass\n",
    "    def forward(self, x):\n",
    "        # x is expected to be of shape (batch_size, seq_len)\n",
    "        batch_size, seq_len = x.size()  # get batch size and sequence length\n",
    "        # create position indices for each token in the sequence\n",
    "        positions = torch.arange(0, seq_len, device=x.device).unsqueeze(0).expand(batch_size, seq_len)\n",
    "        # add token embeddings and position embeddings\n",
    "        x = self.token_embedding(x) + self.position_embedding(positions)\n",
    "        # apply dropout to the embeddings\n",
    "        x = self.dropout(x)\n",
    "        # pass the embeddings through the transformer encoder\n",
    "        encoded = self.encoder(x)\n",
    "        # return the encoded output\n",
    "        return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7cc080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dccb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, output_size, embedding_size, num_heads, hidden_size, num_layers, max_len, p):\n",
    "        # call the parent class constructor\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "\n",
    "        # create token embedding layer for output tokens\n",
    "        self.token_embedding = nn.Embedding(output_size, embedding_size)\n",
    "        # create position embedding layer for positional information\n",
    "        self.position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        # create dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(p)\n",
    "\n",
    "        # create a transformer decoder layer with specified parameters\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=embedding_size,      # set the embedding dimension\n",
    "            nhead=num_heads,             # set the number of attention heads\n",
    "            dim_feedforward=hidden_size, # set the hidden size for feedforward network\n",
    "            dropout=p,                   # set dropout probability\n",
    "            batch_first=True             # use (batch, seq, embed) format\n",
    "        )\n",
    "        # stack multiple decoder layers to form the full decoder\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        # create a linear layer to project decoder output to vocab size\n",
    "        self.fc_out = nn.Linear(embedding_size, output_size)\n",
    "\n",
    "    def forward(self, x, memory):\n",
    "        # x: (batch_size, tgt_seq_len) - input tokens for the decoder\n",
    "        # memory: (batch_size, src_seq_len, embedding_size) - encoder outputs\n",
    "\n",
    "        # get batch size and target sequence length\n",
    "        batch_size, tgt_seq_len = x.size()\n",
    "        # create position indices for each token in the sequence\n",
    "        positions = torch.arange(0, tgt_seq_len, device=x.device).unsqueeze(0).expand(batch_size, tgt_seq_len)\n",
    "        # add token embeddings and position embeddings\n",
    "        x = self.token_embedding(x) + self.position_embedding(positions)\n",
    "        # apply dropout to the embeddings\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # generate a causal mask for the decoder to prevent attending to future tokens\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len).to(x.device)\n",
    "\n",
    "        # pass the embeddings and encoder memory through the transformer decoder\n",
    "        decoded = self.decoder(x, memory, tgt_mask=tgt_mask)\n",
    "        # project the decoder output to the vocabulary size\n",
    "        output = self.fc_out(decoded)\n",
    "        # return the output logits\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6361d11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5379b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerSeq2Seq(\n",
      "  (encoder): TransformerEncoder(\n",
      "    (token_embedding): Embedding(2197, 256)\n",
      "    (position_embedding): Embedding(100, 256)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (token_embedding): Embedding(2350, 256)\n",
      "    (position_embedding): Embedding(100, 256)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.1, inplace=False)\n",
      "          (dropout2): Dropout(p=0.1, inplace=False)\n",
      "          (dropout3): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (fc_out): Linear(in_features=256, out_features=2350, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the transformer-based sequence-to-sequence model class\n",
    "class TransformerEncoderDecoder(nn.Module):\n",
    "    # initialize the model with encoder and decoder\n",
    "    def __init__(self, encoder, decoder):\n",
    "        # call the parent class constructor\n",
    "        super(TransformerEncoderDecoder, self).__init__()\n",
    "        # store the encoder\n",
    "        self.encoder = encoder\n",
    "        # store the decoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    # define the forward pass\n",
    "    def forward(self, src, tgt):\n",
    "        # src: (batch_size, src_seq_len)\n",
    "        # tgt: (batch_size, tgt_seq_len)\n",
    "        # pass the source sequence through the encoder\n",
    "        memory = self.encoder(src)  # (batch_size, src_seq_len, embedding_size)\n",
    "        # pass the target sequence and encoder output through the decoder\n",
    "        output = self.decoder(tgt, memory)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        # return the decoder output\n",
    "        return output\n",
    "\n",
    "# set the input size as the length of the source vocabulary\n",
    "input_size = len(src_vocab)\n",
    "# set the output size as the length of the target vocabulary\n",
    "output_size = len(tgt_vocab)\n",
    "# set the embedding size for both encoder and decoder\n",
    "embedding_size = 256\n",
    "# set the number of attention heads\n",
    "num_heads = 8\n",
    "# set the hidden size for the feedforward network\n",
    "hidden_size = 512\n",
    "# set the number of transformer layers\n",
    "num_layers = 3\n",
    "# set the maximum sequence length\n",
    "max_len = 100\n",
    "# set the dropout probability\n",
    "dropout = 0.1\n",
    "\n",
    "# create the transformer encoder with the specified parameters\n",
    "encoder = TransformerEncoder(\n",
    "    input_size, embedding_size, num_heads, hidden_size, num_layers, max_len, dropout\n",
    ").to(device)\n",
    "# create the transformer decoder with the specified parameters\n",
    "decoder = TransformerDecoder(\n",
    "    output_size, embedding_size, num_heads, hidden_size, num_layers, max_len, dropout\n",
    ").to(device)\n",
    "# create the transformer sequence-to-sequence model using the encoder and decoder\n",
    "model = TransformerSeq2Seq(encoder, decoder).to(device)\n",
    "# print the model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "944ccb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence_tokens, src_vocab, tgt_vocab, device, max_length=50):\n",
    "    tokens = ['<sos>'] + sentence_tokens + ['<eos>']\n",
    "    indices = [src_vocab.get(token, src_vocab['<unk>']) for token in tokens]\n",
    "\n",
    "    sentence_tensor = torch.LongTensor(indices).unsqueeze(1).to(device)  # [seq_len, 1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
    "\n",
    "    outputs = [tgt_vocab['<sos>']]\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        prev_token = torch.LongTensor([outputs[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.Decoder_LSTM(prev_token, hidden, cell)\n",
    "            next_token = output.argmax(1).item()\n",
    "\n",
    "        outputs.append(next_token)\n",
    "\n",
    "        if next_token == tgt_vocab['<eos>']:\n",
    "            break\n",
    "\n",
    "    translated_tokens = [list(tgt_vocab.keys())[list(tgt_vocab.values()).index(idx)] for idx in outputs]\n",
    "    return translated_tokens[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59d948",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
