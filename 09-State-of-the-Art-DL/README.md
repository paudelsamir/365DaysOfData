> [!Warning]
> This content is AI-generated and I am refining it based on my needs. Use it at your own risk


| Category                           | Models/Techniques                                                                                                                                                                                                                                    |
|-------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| üåê **Architectures**                | - ‚úÖ [Vision Transformers (ViT, Swin Transformer)](https://arxiv.org/abs/2010.11929)<br>- ‚úÖ [Conformer (audio/vision)](https://arxiv.org/abs/2005.08100)<br>- ‚úÖ [ConvNeXt](https://arxiv.org/abs/2201.03545)<br>- ‚úÖ [EfficientNet](https://arxiv.org/abs/1905.11946)<br>- ‚úÖ [ResNeXt](https://arxiv.org/abs/1611.05431)<br>- ‚úÖ [Hybrid CNN-Transformer models](https://arxiv.org/abs/2103.15808)<br>- ‚úÖ [Modern RNN/GRU/LSTM with attention](https://arxiv.org/abs/1409.0473) |
| üåê **Generative Models**            | - ‚è≥ [StyleGAN2](https://arxiv.org/abs/1912.04958)<br>- ‚è≥ [BigGAN](https://arxiv.org/abs/1809.11096)<br>- ‚è≥ [Pix2Pix](https://arxiv.org/abs/1611.07004)<br>- ‚è≥ [CycleGAN](https://arxiv.org/abs/1703.10593)<br>- ‚è≥ [DDPM (Denoising Diffusion Probabilistic Models)](https://arxiv.org/abs/2006.11239)<br>- ‚è≥ [DDIM](https://arxiv.org/abs/2010.02502)<br>- ‚è≥ [UNet-based diffusion](https://arxiv.org/abs/1505.04597)<br>- ‚è≥ [Variational Autoencoders (VAE, beta-VAE)](https://arxiv.org/abs/1312.6114) |
| üåê **Self-Supervised Learning**     | - ‚è≥ [SimCLR](https://arxiv.org/abs/2002.05709)<br>- ‚è≥ [BYOL](https://arxiv.org/abs/2006.07733)<br>- ‚è≥ [DINO](https://arxiv.org/abs/2104.14294)<br>- ‚è≥ [MoCo v2](https://arxiv.org/abs/2003.04297)<br>- ‚è≥ [Masked Autoencoders (MAE)](https://arxiv.org/abs/2111.06377) |
| üåê **Image/Video Understanding**    | - ‚úÖ [YOLOv7](https://arxiv.org/abs/2207.02696)<br>- ‚è≥ [DETR](https://arxiv.org/abs/2005.12872)<br>- ‚è≥ [SparseRCNN](https://arxiv.org/abs/2011.12450)<br>- ‚è≥ [DeepLabv3+](https://arxiv.org/abs/1802.02611)<br>- ‚è≥ [MaskRCNN](https://arxiv.org/abs/1703.06870)<br>- ‚è≥ [Segment Anything](https://arxiv.org/abs/2304.02643)<br>- ‚è≥ [TimeSformer](https://arxiv.org/abs/2102.05095)<br>- ‚è≥ [SlowFast](https://arxiv.org/abs/1812.03982) |
| üåê **Audio + Speech**               | - ‚è≥ [Wav2Vec2](https://arxiv.org/abs/2006.11477)<br>- ‚è≥ [Conformer (speech)](https://arxiv.org/abs/2005.08100)<br>- ‚è≥ [Audio Spectrogram Transformer (AST)](https://arxiv.org/abs/2104.01778)<br>- ‚è≥ [Speaker recognition/separation (e.g., ECAPA-TDNN)](https://arxiv.org/abs/2005.07143) |
| üåê **Multimodal**                   | - ‚è≥ [CLIP](https://arxiv.org/abs/2103.00020)<br>- ‚è≥ [Visual Question Answering (attention-based)](https://arxiv.org/abs/1512.02902)<br>- ‚è≥ [Audio-Visual Emotion Recognition](https://arxiv.org/abs/1806.09592) |
| üåê **Training Tricks & Optimization** | - ‚úÖ [Cosine/One-cycle learning rate schedules](https://arxiv.org/abs/1608.03983)<br>- ‚úÖ [Mixed precision training](https://arxiv.org/abs/1710.03740)<br>- ‚úÖ [Gradient checkpointing](https://arxiv.org/abs/1604.06174)<br>- ‚úÖ [Data augmentations (CutMix, MixUp, RandAugment)](https://arxiv.org/abs/1905.04899)<br>- ‚è≥ [Loss functions for imbalanced/hard tasks (focal loss, triplet loss)](https://arxiv.org/abs/1708.02002) |


